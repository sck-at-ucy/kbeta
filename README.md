[![CIÂ (macOSÂ arm64)](https://github.com/sck-at-ucy/kbeta/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/sck-at-ucy/kbeta/actions/workflows/ci.yml)

<p align="center">
  <img src="assets/MLX_Kourkoutas.png" width="600"/>
</p>

# kbetaÂ â€“Â *Kourkoutasâ€‘Î² Optimiser* Â Â ğŸŒğŸ¦ğŸš€ğŸ“ˆ

> Reference implementation of **Kourkoutasâ€‘Î²: A Sunspikeâ€‘Driven Adam Optimizer with Desert Flair**
> Published as [arXiv:2508.12996](http://arxiv.org/abs/2508.12996).

This repository provides the optimiser implementation together with example workloads for reproducibility.

---

## Tableâ€¯ofâ€¯Contents
1. [Key ideas](#key-ideas)
2. [Project layout](#project-layout)
3. [Quick start](#quick-start)
4. [Using Kourkoutasâ€‘Î² in your own model](#minimal-example)
5. [Example workloads](#example-workloads)
6. [Tests & linting](#tests--linting)
7. [Citation](#citation)
8. [License](#license)
9. [Contributing & roadmap](#contributing--roadmap)

---

## Key ideas

* **Layerâ€‘wise dynamic Î²â‚‚** driven by a bounded *sunâ€‘spike* signal (gradient norm vs. EMA).
* **Two Î²â‚‚ parameters**: *Î²â‚‚_min* for agility under spikes, *Î²â‚‚_max* for stability when calm.
* **Optional features**: softâ€‘max AMSGrad, trustâ€‘region clipping, adaptive tiny term.
* **Dropâ€‘in compatibility**: recovers **exact Adam** when dynamic Î²â‚‚ and extras are disabled.
* 100â€¯% **Apple MLX** compatible â€“ no PyTorch required.

See the paper for derivations, experiments, and theoretical analysis.

---

## Conceptual overview

### Highâ€‘level intuition â€“ the â€œdesert lizardâ€ view
*Kourkoutasâ€‘Î²* is an Adamâ€‘style optimiser whose secondâ€‘moment decay **Î²â‚‚** is no longer a hardâ€‘wired constant.
Instead, every update computes a **sunâ€‘spike score**â€”a single, cheap scalar that compares the current gradient magnitude to its exponentiallyâ€‘weighted history.  We then **map that score to Î²â‚‚ on the fly**:

| Sunâ€‘spike | Lizard metaphor | Adaptive behaviour |
|-----------|-----------------|--------------------|
| **High**  | The desert sun is scorching â€” the lizard is â€œfully warmed upâ€ and sprints. | **Lower Î²â‚‚ toward Î²â‚‚,min** â†’ secondâ€‘moment memory shortens, allowing rapid, large parameter moves. |
| **Low**   | Itâ€™s cool; the lizard feels sluggish and takes cautious steps. | **Raise Î²â‚‚ toward Î²â‚‚,max** â†’ longer memory, filtering noise and producing steadier updates. |

Because the sunâ€‘spike diagnostic **exists only in Kourkoutasâ€‘Î²**, the method can be viewed as *Adam with a temperatureâ€‘controlled Î²â‚‚ schedule*: warm gradients trigger exploration; cooler gradients favour exploitation and stability.

---

## Project layout

```
kbeta
â”œâ”€â”€ src/kbeta/                   # pip package
â”‚Â Â  â”œâ”€â”€ __init__.py              # exports KourkoutasBeta / KourkoutasSoftmaxFlex
â”‚Â Â  â””â”€â”€ optim/
â”‚Â Â      â””â”€â”€ kbeta_softmax.py     # implementation
â”‚
â”œâ”€â”€ examples/
â”‚Â Â  â””â”€â”€ transformer_char_lm/     # TestbedÂ D: characterâ€‘level LM on smallâ€‘enwik8
â”‚
â”œâ”€â”€ tests/                       # pytest suite (smoke + ablation tests)
â”œâ”€â”€ assets/                      # logo and figures
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md                    # you are here
```

---

## Quick start

```bash
# 1. clone your fork
git clone git@github.com:<YOUR-USERNAME>/kbeta.git
cd kbeta

# 2. create a fresh virtualenv
python -m venv .venv && source .venv/bin/activate

# 3. editable install + dev extras
pip install -e ".[dev]"

# 4. run the smoke + ablation tests
pytest -q
```

---

## Minimal example

```import time
import mlx.core as mx
import mlx.nn as nn
from kbeta import KourkoutasBeta

num_features, num_examples, num_iters, lr = 100, 1000, 1000, 0.01

# True parameters and data
w_star = mx.random.normal((num_features,))
X = mx.random.normal((num_examples, num_features))
y = X @ w_star + 1e-2 * mx.random.normal((num_examples,))

# Simple model with one parameter
class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.w = mx.zeros((num_features,))

    def __call__(self, x):
        return x @ self.w

model = Model()

def loss_fn(m):
    return 0.5 * mx.mean(mx.square(m(X) - y))

opt = KourkoutasBeta(learning_rate=lr)
opt.init(model.parameters())

grad_fn = nn.value_and_grad(model,loss_fn)

tic = time.time()
for _ in range(num_iters):
    loss, grads = grad_fn(model)
    opt.update(model, grads)
    mx.eval(model.parameters())
toc = time.time()

error_norm = float(mx.linalg.norm(model.w - w_star))
print(f"Loss={loss.item():.5f}, L2|w-w*|={error_norm:.5f}, Throughput={num_iters/(toc-tic):.1f} it/s")
```

---

## Example workloads

| Folder | Paper section | What it shows | How to run |
|--------|---------------|---------------|------------|
| `examples/transformer_char_lm` | Â§â€¯6.4 (TestbedÂ D) | Characterâ€‘level LM on *smallâ€‘enwik8* | `python examples/transformer_char_lm/testbed_d.py --text ./data/small_enwik8.txt --opt kbeta` |

The 2â€‘D Transformer (Heat2D, TestbedÂ A) and 3â€‘D PINN (Heat3D, TestbedÂ B) are released as separate repositories:
- [kbeta-transformer2d](https://github.com/sck-at-ucy/kbeta-transformer2d)
- [kbeta-pinn3d](https://github.com/sck-at-ucy/kbeta-pinn3d)

---

## Tests & linting

```bash
pytest                 # unit & ablation tests
ruff check .           # style / imports / naming
pre-commit run --all   # run all hooks (if installed)
```

Continuous Integration (CI) runs these checks automatically.

---

## Citation

If you use this code or method in your research, please cite:

```
@article{Kassinos2025Kourkoutas,
  title   = {Kourkoutas-Î²: A Sunspike-Driven Adam Optimizer with Desert Flair},
  author  = {Stavros Kassinos},
  journal = {arXiv preprint arXiv:2508.12996},
  year    = {2025},
  url     = {http://arxiv.org/abs/2508.12996}
}
```

---

## License

This work is distributed under the **MIT License**â€”see [`LICENSE`](LICENSE) for details.

---

## Contributing & roadmap

We welcome issues & PRs!

Planned milestones:

1. **v0.1.0** â€“ optimiser + charâ€‘LM demo (public).
2. **v0.2.0** â€“ PDE workloads migrated to their own repos.
3. **v1.0.0** â€“ journal publication, pip wheels for macOS/Apple Silicon & Linux.

Happy sprinting in the (numerical) desert ğŸŒğŸ¦ğŸš€ğŸ“ˆ
